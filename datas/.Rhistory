setwd("C:/Users/MK/DataSientist/S_Project/datas")
#예측변수들의 상대적 중요도-----------------------------------------
relweights <- function(fit,...){
R <- cor(fit$model)
nvar <- ncol(R)
rxx <- R[2:nvar, 2:nvar]
rxy <- R[2:nvar, 1]
svd <- eigen(rxx)
evec <- svd$vectors
ev <- svd$values
delta <- diag(sqrt(ev))
lambda <- evec %*% delta %*% t(evec)
lambdasq <- lambda ^ 2
beta <- solve(lambda) %*% rxy
rsquare <- colSums(beta ^ 2)
rawwgt <- lambdasq %*% beta ^ 2
import <- (rawwgt / rsquare) * 100
import <- as.data.frame(import)
row.names(import) <- names(fit$model[2:nvar])
names(import) <- "Weights"
import <- import[order(import),1, drop=FALSE]
dotchart(import$Weights, labels=row.names(import),
xlab="% of R-Square", pch=19,
main="Relative Importance of Predictor Variables",
sub=paste("Total R-Square=", round(rsquare, digits=3)),
...)
return(import)
}
# 1. main
#파일로드-------------------------------------------------
trainData <- read.csv("R_train_main.csv",header=T)
testData <- read.csv("R_test_main.csv",header=T)
attach(trainData)
attach(testData)
#1차 변수선택-------------------------------------------------
null=lm(label~1, data=trainData) #x를 하나도 포함하지 않음. 상수만 들어감
full=lm(label~., data=trainData, na.action=na.exclude) #x변수를 모두 포함
#즉 가장 작은 모델 null, 큰 모델 full
#stepwise
out = step(null, scope=list(upper=full), direction="both")
myformula = formula(out)
myformula
#AIC결과는 작을수록 좋음
#다중공선성확인-------------------------------------------
#정의 : 회귀 분석에서 사용된 모형의 일부 예측 변수가 다른 예측 변수와 상관 정도가 높아,
#데이터 분석 시 부정적인 영향을 미치는 현상을 말한다
install.packages("car")
library(car)
vif(glm)
#다중회귀분석시엔 vif부터 한다! 문제 일으키는 변수 있으면 빼고 다시 vif해본다. 반복
#VIF계산시 10보다 크면 다중공선성이 존재한다.
S2년전사업성과1
install.packages("caret")
library(caret)
nearZeroVar(trainData, saveMetrics)
#변수제거 후 AIC 비교
#다중공선성이 큰 변수 제거 후 비교
install.packages("car")
library(car)
##glm(로지스틱 회귀모델)---------------------------------------------------------
glm<- glm(myformula , data = trainData, family = "binomial")
summary(glm)$adj.r.squared
relweights(glm, col="blue")
setwd("C:/Users/MK/DataSientist/S_Project/datas")
#예측변수들의 상대적 중요도-----------------------------------------
relweights <- function(fit,...){
R <- cor(fit$model)
nvar <- ncol(R)
rxx <- R[2:nvar, 2:nvar]
rxy <- R[2:nvar, 1]
svd <- eigen(rxx)
evec <- svd$vectors
ev <- svd$values
delta <- diag(sqrt(ev))
lambda <- evec %*% delta %*% t(evec)
lambdasq <- lambda ^ 2
beta <- solve(lambda) %*% rxy
rsquare <- colSums(beta ^ 2)
rawwgt <- lambdasq %*% beta ^ 2
import <- (rawwgt / rsquare) * 100
import <- as.data.frame(import)
row.names(import) <- names(fit$model[2:nvar])
names(import) <- "Weights"
import <- import[order(import),1, drop=FALSE]
dotchart(import$Weights, labels=row.names(import),
xlab="% of R-Square", pch=19,
main="Relative Importance of Predictor Variables",
sub=paste("Total R-Square=", round(rsquare, digits=3)),
...)
return(import)
}
# 1. main
#파일로드-------------------------------------------------
trainData <- read.csv("R_train_main.csv",header=T)
testData <- read.csv("R_test_main.csv",header=T)
attach(trainData)
attach(testData)
#1차 변수선택-------------------------------------------------
null=lm(label~1, data=trainData) #x를 하나도 포함하지 않음. 상수만 들어감
full=lm(label~., data=trainData, na.action=na.exclude) #x변수를 모두 포함
#즉 가장 작은 모델 null, 큰 모델 full
#stepwise
out = step(null, scope=list(upper=full), direction="both")
myformula = formula(out)
myformula
#AIC결과는 작을수록 좋음
##glm(로지스틱 회귀모델)---------------------------------------------------------
glm<- glm(myformula , data = trainData, family = "binomial")
summary(glm)$adj.r.squared
relweights(glm, col="blue")
glm
summary(glm)$adj.r.squared
vif(glm)
#아래 함수는 AIC 개념만 참고 실제 결과와 차이가 있음.
aic <- function(data, formula){
myaic = nrow(data)*(log(2*pi)+1+log((sum(formula$residuals^2)/nrow(data))))
+((length(formula$coefficients)+1)*2)
}
aic
summary(glm)
#교차검증 -------------------------------------------------
# confusion matrix (trainData)
y = trainData$label #실제
p = predict.glm(myglmA, trainData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
# confusion matrix (trainData)
y = trainData$label #실제
p = predict.glm(glm, trainData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
# confusion matrix (testdata)
y = testData$label #실제
p = predict.glm(glm, testData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
# 2. all
#파일로드-------------------------------------------------
trainData <- read.csv("R_train.csv",header=T)
testData <- read.csv("R_test.csv",header=T)
attach(trainData)
attach(testData)
#1차 변수선택-------------------------------------------------
null=lm(label~1, data=trainData) #x를 하나도 포함하지 않음. 상수만 들어감
full=lm(label~., data=trainData, na.action=na.exclude) #x변수를 모두 포함
#즉 가장 작은 모델 null, 큰 모델 full
#stepwise
out = step(null, scope=list(upper=full), direction="both")
# all 기준의 myformula 결과 셋팅
myformula <- label ~ X6000306015O0 + S41B0M5004O0 + S41B0D1009O0 + X6000303005O0 +
X6000901002D1 + X1001113580O0 + DR00000051 + X6000908001D7 +
S41B0D1007O0 + P6000901017O0 + X6000908001D2 + X6000901045O0 +
DR00000127 + DR00000082 + DR00000103 + S41B0D1008O0 + X6000901042D1 +
X6000909101J1 + X6000906020J1 + DR00000027 + P6000205014O0 +
X6000601032O0 + X6000403002O0 + DR00000156 + X6000909011J1 +
X6000908001D3 + DR00000136 + X6000204003O0 + X3001212005O0 +
X6000105004O0 + DR00000052 + DR00000088 + I310021231O0 +
X3001403004J0 + I310020332O0 + X6000904001D3 + X6000902001D2 +
X6000901074O0 + I310009930O0 + P6000201003O0 + X6000901070J1 +
DR00000033 + X6000906001J1 + X6000208015O0 + I310020732O0 +
X6000902001J1 + X6000909001D1 + X6000902001O0 + X6000902003O0 +
TOPCOM0005D1 + TOPCOM3160D1 + X6000901045J1 + P6000705001O0 +
P6000903016O0 + X6000902003D3 + X6000111001J1 + X6000402001J1 +
X6000306003J1 + X6000906020O0 + X6000901001D3 + X6000105010O0 +
X6000307007O0 + X6000312004O0 + S41B0M5008O0 + S41B0M5007O0 +
S41B0D1005J1 + S41B0D1006O0 + DR00000053 + X6000601024J1 +
X1001113580J1 + X6000906020D1 + DR00000134 + S41B0M3007O0 +
I31000350FO0 + I31000380FO0 + P6000903001O0 + P6000904001O0 +
X1001113580D2 + X6000991010J1 + I310006600O0 + DR00000161 +
DR00000044 + DR00000144 + X6000901005O0 + X6000904001D5 +
BK102Y0462 + S41000210FD2 + P6000208004O0 + P6000205031O0 +
X1001113580D1 + X6000906001D2 + P6000201008O0 + I31000205FO0 +
P6000304003O0 + X6000906009D2 + DR00000063 + P6000909023O0 +
DR00000034 + P6000805001O0 + I310020932O0 + S410005000D1 +
DR00000142 + S41B0M5009O0 + P6000103001O0 + X6000903001J1 +
X6000403001O0 + X6000207003O0 + X6000312001O0 + DR00000095 +
DR00000057 + TOPCOM0630D1
##glm(로지스틱 회귀모델)---------------------------------------------------------
glm<- glm(myformula , data = trainData, family = "binomial")
summary(glm)$adj.r.squared
relweights(glm, col="blue")
#다중공선성확인-------------------------------------------
#정의 : 회귀 분석에서 사용된 모형의 일부 예측 변수가 다른 예측 변수와 상관 정도가 높아,
#데이터 분석 시 부정적인 영향을 미치는 현상을 말한다
install.packages("car")
library(car)
vif(glm)
#다중회귀분석시엔 vif부터 한다! 문제 일으키는 변수 있으면 빼고 다시 vif해본다. 반복
#VIF계산시 10보다 크면 다중공선성이 존재한다.
install.packages("car")
vif(glm)
#다중회귀분석시엔 vif부터 한다! 문제 일으키는 변수 있으면 빼고 다시 vif해본다. 반복
#VIF계산시 10보다 크면 다중공선성이 존재한다.
library(car)
vif(glm)
#다중회귀분석시엔 vif부터 한다! 문제 일으키는 변수 있으면 빼고 다시 vif해본다. 반복
#VIF계산시 10보다 크면 다중공선성이 존재한다.
summary(glm)
#교차검증 -------------------------------------------------
# confusion matrix (trainData)
y = trainData$label #실제
p = predict.glm(glm, trainData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
# confusion matrix (testdata)
y = testData$label #실제
p = predict.glm(glm, testData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
# 1. main
#파일로드-------------------------------------------------
trainData <- read.csv("R_train_main.csv",header=T)
testData <- read.csv("R_test_main.csv",header=T)
attach(trainData)
attach(testData)
#1차 변수선택-------------------------------------------------
null=lm(label~1, data=trainData) #x를 하나도 포함하지 않음. 상수만 들어감
full=lm(label~., data=trainData, na.action=na.exclude) #x변수를 모두 포함
#즉 가장 작은 모델 null, 큰 모델 full
#stepwise
out = step(null, scope=list(upper=full), direction="both")
myformula = formula(out)
myformula
#AIC결과는 작을수록 좋음
##glm(로지스틱 회귀모델)---------------------------------------------------------
glm<- glm(myformula , data = trainData, family = "binomial")
summary(glm)
#교차검증 -------------------------------------------------
# confusion matrix (trainData)
y = trainData$label #실제
p = predict.glm(glm, trainData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
#write.csv(p, "trainData_Pred_y.csv", row.names=TRUE) #!!! 주의
write.csv(p, "trainData_Pred_y.csv", row.names=TRUE) #!!! 주의
# confusion matrix (testdata)
y = testData$label #실제
p = predict.glm(glm, testData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
write.csv(p, "trainData__Pred_y.csv", row.names=TRUE) #!!! 주의
#교차검증 -------------------------------------------------
# confusion matrix (trainData)
y = trainData$label #실제
p = predict.glm(glm, trainData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
write.csv(p, "trainData_Pred_y.csv", row.names=TRUE) #!!! 주의
# confusion matrix (testdata)
y = testData$label #실제
p = predict.glm(glm, testData, type ="response")	#예측 부도여부
p = ifelse(p>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
write.csv(p, "testData_Pred_y.csv", row.names=TRUE) #!!! 주의
#교차검증 -------------------------------------------------
# confusion matrix (trainData)
y = trainData$label #실제
pred = predict.glm(glm, trainData, type ="response")	#예측 부도여부
p = ifelse(pred>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
write.csv(pred, "trainData_Pred_y.csv", row.names=TRUE) #!!! 주의
# confusion matrix (testdata)
y = testData$label #실제
pred = predict.glm(glm, testData, type ="response")	#예측 부도여부
p = ifelse(pred>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
write.csv(pred, "testData_Pred_y.csv", row.names=TRUE) #!!! 주의
# main 기준의 myformula 결과 셋팅
myformula <- label ~ X6000908001D7 + S41B0D1009O0 + DR00000082 + S41000210FD1 +
DR00000113 + X6000908001D2 + X6000901001D3 + X6000901002D1 +
CO10100170O0 + X6000904001D3 + DR00000156 + FNMKFN02 + DR00000136 +
X6000403001O0 + X6000908001D3 + X6000906001D6 + X6000903016D1 +
X6000903001D2 + X6000902001D2 + DR00000052 + X6000201001O0 +
X6000901002D3 + S41000210FD2 + X6000207003O0
setwd("C:/Users/MK/DataSientist/S_Project/datas")
# 1. main
#파일로드-------------------------------------------------
trainData <- read.csv("R_train_main.csv",header=T)
testData <- read.csv("R_test_main.csv",header=T)
attach(trainData)
attach(testData)
##glm(로지스틱 회귀모델)---------------------------------------------------------
glm<- glm(myformula , data = trainData, family = "binomial")
summary(glm)$adj.r.squared
relweights(glm, col="blue")
summary(glm)$adj.r.squared
summary(glm)
#교차검증 -------------------------------------------------
# confusion matrix (trainData)
y = trainData$label #실제
pred = predict.glm(glm, trainData, type ="response")	#예측 부도여부
p = ifelse(pred>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
write.csv(pred, "trainData_Pred_y.csv", row.names=TRUE) #!!! 주의
# confusion matrix (testdata)
y = testData$label #실제
pred = predict.glm(glm, testData, type ="response")	#예측 부도여부
p = ifelse(pred>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
write.csv(pred, "testData_Pred_y.csv", row.names=TRUE) #!!! 주의
#교차검증 -------------------------------------------------
# confusion matrix (trainData)
y = trainData$label #실제
pred = predict.glm(glm, trainData, type ="response")	#예측 부도여부
p = ifelse(pred>0.5,1,0)
is_correct <- p == y
sum(is_correct)
sum(is_correct)/NROW(is_correct) ##accuracy
table(y,p)
## csv 파일로 저장 (절대 주의!!)
write.csv(pred, "trainData_Pred_y.csv", row.names=TRUE) #!!! 주의
