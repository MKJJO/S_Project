{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원의 저주\n",
    "\n",
    "차원이 증가하면 그것을 표현하기 위한 데이터의 수가 기하급수적으로 증가한다.\n",
    "\n",
    "(일정 차원이 넘으면 분류기의 성능은 점점 떨어져 0으로 수렴함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AE는 입력값보다 작은 차원을 갖는 hidden layer를 이용해 데이터 속에 숨어있는 변수를 발굴할 수 있게 해준다.\n",
    "\n",
    "흔히 사용되는 PCA는 선형적인 한계가 있다. 하지만 AE는 뉴런이 갖고 있는 non-linear 및 constraints로 인해 훨씬 뛰어난 차원 축소 능력을 가지고 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<VAE와 AE의 차이>\n",
    "\n",
    "VAE는 AE와 비슷하지만 약간 다른점이 존재한다. z가 training data와 특별이 관련이 없이 단순히 계산 중간에 나오는 한 값일 뿐이라면 VAE에서의 latent variable인 z는 continouous한 분포를 갖는 random variable이라는 점이 중요한 차이다. 이 latent variable z의 분포는 training 과정에서의 data로부터 학습된다.\n",
    "(즉, VAE는 z를 좀 더 다루기 쉬운 우리가 잘 아는 분포(가우시안)의 형태를 띄게 만들어 지는 것\n",
    "\n",
    "결론적으로, AE와 다른 점은 z 하나하나를 \"모으고\", \"흔들어서\", z 공간을 더 촘촘히 채워줘서 더 유용한 z 공간을 만든다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://blog.naver.com/PostView.nhn?blogId=laonple&logNo=220880813236&parentCategoryNo=&categoryNo=18&viewDate=&isShowPopularPosts=true&from=search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA vs VAE vs GAN\n",
    "https://spark-in.me/post/playing-with-vae-umap-pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IN 파일\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Add, Multiply\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import mnist\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 변경값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구분 최초 설정 필요\n",
    "\n",
    "df = 'core'\n",
    "target_temp_df = 'Y'  # 정상:부실의 데이터 비율을 맞추기 위한 데이터셋을 사용할 건지 여부 (데이터스케일링 쥬피터 결과 기준)\n",
    "\n",
    "# main/all/core 3가지로 설정 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# core설정시 확인해야 함\n",
    "# R을 통해 확인한 stepwise 유의 변수 리스트\n",
    "core_factors = ['DR00000136','6000201001O0','6000903016D1','FNMKFN02','6000901002D1','S41000210FD1',\n",
    "'6000207003O0','DR00000052','6000906001D6','DR00000156','6000901001D3','DR00000082',\n",
    "'S41000210FD2','6000902001D2','6000908001D3','6000904001D3','6000908001D2','S41B0D1009O0',\n",
    "'6000901002D3','6000903001D2','6000403001O0','CO10100170O0','DR00000113','6000908001D7']\n",
    "\n",
    "#  키별로 비율 배분이 잘 됐는지 확인\n",
    "if df == 'all':\n",
    "    max_idx = 707\n",
    "else:\n",
    "    max_idx = 124\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # 파이썬 객체저장을 위한 모듈\n",
    "\n",
    "# 파이썬 객체 읽어오기\n",
    "\n",
    "if target_temp_df != 'Y':\n",
    "    if df == 'all':\n",
    "        with open('./pickles/dataset_all.p', 'rb') as file:    # hello.txt 파일을 바이너리 읽기 모드(rb)로 열기\n",
    "            train_set = pickle.load(file)\n",
    "            test_set = pickle.load(file)\n",
    "    else:\n",
    "        with open('./pickles/dataset_main.p', 'rb') as file:    # hello.txt 파일을 바이너리 읽기 모드(rb)로 열기\n",
    "            train_set = pickle.load(file)\n",
    "            test_set = pickle.load(file)\n",
    "else:\n",
    "# 정상:부실의 데이터 비율 조정 기준\n",
    "    if df == 'all':\n",
    "        with open('./pickles/data6vs4_all.p', 'rb') as file:    # hello.txt 파일을 바이너리 읽기 모드(rb)로 열기\n",
    "            temp_train_set = pickle.load(file)\n",
    "            temp_test_set = pickle.load(file)\n",
    "            af_cols = pickle.load(file)\n",
    "    else:\n",
    "        with open('./pickles/data6vs4_main.p', 'rb') as file:    # hello.txt 파일을 바이너리 읽기 모드(rb)로 열기\n",
    "            temp_train_set = pickle.load(file)\n",
    "            temp_test_set = pickle.load(file)\n",
    "            af_cols = pickle.load(file)\n",
    "            \n",
    "    # 필요없는 열 삭제\n",
    "    train_set = temp_train_set.drop(['index', 0, max_idx-1,max_idx],axis=1)  # 열삭제\n",
    "    test_set = temp_test_set.drop(['index', 0, max_idx-1,max_idx],axis=1)  # 열삭제\n",
    "    x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "    # 항목명 (열명) 셋팅\n",
    "    factor_cols = list(af_cols[1:-2])\n",
    "    train_set.columns = factor_cols\n",
    "    test_set.columns = factor_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core인 경우 main에서 핵심 변수만 추림\n",
    "\n",
    "if df == 'core':\n",
    "    final_factors = ['key', 'industry', 'label']\n",
    "    final_factors = final_factors + core_factors\n",
    "    train_set = train_set[final_factors]\n",
    "    test_set = test_set[final_factors]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('core', (755, 27), (333, 27))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분리 및 타입변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "cols = train_set.columns.values\n",
    "train_info = train_set[cols[0:3]]\n",
    "x_train = train_set[cols[3:]]\n",
    "y_train = train_set['label']\n",
    "train_len = x_train.shape[0]\n",
    "\n",
    "cols = test_set.columns.values\n",
    "test_info = test_set[cols[0:3]]\n",
    "x_test = test_set[cols[3:]]\n",
    "y_test = test_set['label']\n",
    "test_len = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 24), (755,))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE 모델링 ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = x_train.shape[1] # 가로 열, 주의! 설명항목 제외\n",
    "n = x_train.shape[0] # 세로 행 \n",
    "original_dim = m \n",
    "intermediate_dim = 256\n",
    "\n",
    "# latent vector  z 의 차원   32\n",
    "if m >= 100:\n",
    "    latent_dim = 32\n",
    "elif m >= 50:\n",
    "    latent_dim = 16\n",
    "else:\n",
    "    latent_dim = 10\n",
    "    \n",
    "batch_size = 100 # 100\n",
    "epochs = 50   # 50\n",
    "epsilon_std = 1 # 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE loss 함수 참고\n",
    "https://www.facebook.com/groups/TensorFlowKR/permalink/524873987853664/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nll(y_true, y_pred):\n",
    "    \"\"\" Negative log likelihood (Bernoulli). \"\"\"\n",
    "\n",
    "    # keras.losses.binary_crossentropy gives the mean\n",
    "    # over the last axis. we require the sum\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "\n",
    "class KLDivergenceLayer(Layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    KL을 사용하는 의미는 q0(z|x) ( x 를 받고 z 를 뱉어내는 인코더 ) 와 \n",
    "    p(z) = Normal distribution (mean= 0 stddv = 1) 의 정보량의 차이가 얼마나 나는가를 보기 위해 사용\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" \n",
    "    VAE loss = reconstruction_loss + regularizaion_loss\n",
    "    \n",
    "    1) reconstruction : AE의 입력 X와 출력 X'의 차이에 대한 loss\n",
    "    2) reqularization : -0.5 * (1 + log_z_var - z_mean^2 - z_var)\n",
    "       z_mean과 z_var는 z들의 (다시 말해 z 전체의) mean과 var가 아니다. \n",
    "       z 각각, 하나하나의 mean과 var이다. 하나하나의 mean과 var 용어 때문에 헷갈린다면 \n",
    "       (AE에서의 z와 같은) z와 z_흔들기정도 정도로 이해하면 더 쉽다.\n",
    "       x 하나하나에 대한 z 하나하나를 확률적으로 보고 학습 하겠다는 것이다.\n",
    "       \n",
    "    * z_var - log_z_var는 z_var가 1일때 최소화 된다. 즉, z_var를 1에 가깝게, 1보다 너무 크지도 작지도 않게 하라는 뜻이다\n",
    "      \"랜덤하게 흔드는\" 것을 어느 정도는 적당히 흔들어 주라는 뜻이 된다. 그래야 거기서 얘기한 \"공간 채우기\" 효과를 낼 수 있기 때문이다.\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Sequential([\n",
    "    Dense(intermediate_dim, input_dim=latent_dim, activation='relu'),\n",
    "    Dense(original_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "z_mu = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
    "z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n",
    "\n",
    "\"\"\"\n",
    "z를 학습할때마다 랜덤하게 흔들어줌\n",
    "z공간을 더 많이 학습된 공간으로 채워 준다. 결국 Decoder 입장에서 z 공간이 훨씬 더 믿을 만한 (유용한) 공간이 됨\n",
    "\"\"\"\n",
    "eps = Input(tensor=K.random_normal(stddev=epsilon_std,\n",
    "                                   shape=(K.shape(x)[0], latent_dim)))\n",
    "z_eps = Multiply()([z_sigma, eps])\n",
    "z = Add()([z_mu, z_eps])\n",
    "\n",
    "x_pred = decoder(z)\n",
    "\n",
    "vae = Model(inputs=[x, eps], outputs=x_pred)\n",
    "vae.compile(optimizer='rmsprop', loss=nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "x_train = x_train.reshape(-1, original_dim)\n",
    "x_test = x_test.reshape(-1, original_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 24), (333, 24))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 755 samples, validate on 755 samples\n",
      "Epoch 1/50\n",
      "755/755 [==============================] - 2s 2ms/step - loss: -17.2289 - val_loss: -134.8250\n",
      "Epoch 2/50\n",
      "755/755 [==============================] - 0s 70us/step - loss: -258.3753 - val_loss: -365.1105\n",
      "Epoch 3/50\n",
      "755/755 [==============================] - 0s 86us/step - loss: -391.8857 - val_loss: -429.1524\n",
      "Epoch 4/50\n",
      "755/755 [==============================] - 0s 74us/step - loss: -441.1714 - val_loss: -463.6643\n",
      "Epoch 5/50\n",
      "755/755 [==============================] - 0s 75us/step - loss: -472.8354 - val_loss: -486.3717\n",
      "Epoch 6/50\n",
      "755/755 [==============================] - 0s 71us/step - loss: -490.5702 - val_loss: -501.8057\n",
      "Epoch 7/50\n",
      "755/755 [==============================] - 0s 86us/step - loss: -504.8860 - val_loss: -512.3602\n",
      "Epoch 8/50\n",
      "755/755 [==============================] - 0s 81us/step - loss: -515.1018 - val_loss: -514.9441\n",
      "Epoch 9/50\n",
      "755/755 [==============================] - 0s 91us/step - loss: -521.5238 - val_loss: -525.5871\n",
      "Epoch 10/50\n",
      "755/755 [==============================] - 0s 78us/step - loss: -527.9885 - val_loss: -532.9331\n",
      "Epoch 11/50\n",
      "755/755 [==============================] - 0s 86us/step - loss: -534.1171 - val_loss: -527.8293\n",
      "Epoch 12/50\n",
      "755/755 [==============================] - ETA: 0s - loss: -544.35 - 0s 91us/step - loss: -535.0129 - val_loss: -533.8682\n",
      "Epoch 13/50\n",
      "755/755 [==============================] - 0s 75us/step - loss: -540.2559 - val_loss: -544.8569\n",
      "Epoch 14/50\n",
      "755/755 [==============================] - 0s 90us/step - loss: -543.9893 - val_loss: -546.7390\n",
      "Epoch 15/50\n",
      "755/755 [==============================] - 0s 89us/step - loss: -548.5063 - val_loss: -540.7750\n",
      "Epoch 16/50\n",
      "755/755 [==============================] - 0s 81us/step - loss: -549.0142 - val_loss: -552.4841\n",
      "Epoch 17/50\n",
      "755/755 [==============================] - 0s 82us/step - loss: -553.1426 - val_loss: -557.4981\n",
      "Epoch 18/50\n",
      "755/755 [==============================] - 0s 100us/step - loss: -556.6421 - val_loss: -557.8978\n",
      "Epoch 19/50\n",
      "755/755 [==============================] - 0s 96us/step - loss: -558.6275 - val_loss: -558.4686\n",
      "Epoch 20/50\n",
      "755/755 [==============================] - 0s 77us/step - loss: -561.3329 - val_loss: -562.9429\n",
      "Epoch 21/50\n",
      "755/755 [==============================] - 0s 87us/step - loss: -562.3376 - val_loss: -558.3518\n",
      "Epoch 22/50\n",
      "755/755 [==============================] - 0s 73us/step - loss: -563.5049 - val_loss: -554.0108\n",
      "Epoch 23/50\n",
      "755/755 [==============================] - 0s 116us/step - loss: -561.7416 - val_loss: -565.3896\n",
      "Epoch 24/50\n",
      "755/755 [==============================] - 0s 91us/step - loss: -566.2010 - val_loss: -567.7112\n",
      "Epoch 25/50\n",
      "755/755 [==============================] - 0s 94us/step - loss: -566.1286 - val_loss: -569.2645\n",
      "Epoch 26/50\n",
      "755/755 [==============================] - 0s 129us/step - loss: -567.0978 - val_loss: -565.7196\n",
      "Epoch 27/50\n",
      "755/755 [==============================] - 0s 135us/step - loss: -569.6839 - val_loss: -570.5338\n",
      "Epoch 28/50\n",
      "755/755 [==============================] - 0s 106us/step - loss: -569.4486 - val_loss: -571.3559\n",
      "Epoch 29/50\n",
      "755/755 [==============================] - 0s 129us/step - loss: -570.0236 - val_loss: -571.4892\n",
      "Epoch 30/50\n",
      "755/755 [==============================] - 0s 96us/step - loss: -571.3944 - val_loss: -572.4930\n",
      "Epoch 31/50\n",
      "755/755 [==============================] - 0s 110us/step - loss: -572.8227 - val_loss: -569.7763\n",
      "Epoch 32/50\n",
      "755/755 [==============================] - 0s 96us/step - loss: -570.8733 - val_loss: -571.7546\n",
      "Epoch 33/50\n",
      "755/755 [==============================] - 0s 118us/step - loss: -573.4473 - val_loss: -575.3083\n",
      "Epoch 34/50\n",
      "755/755 [==============================] - 0s 99us/step - loss: -574.4099 - val_loss: -572.4230\n",
      "Epoch 35/50\n",
      "755/755 [==============================] - 0s 96us/step - loss: -572.5627 - val_loss: -569.1396\n",
      "Epoch 36/50\n",
      "755/755 [==============================] - 0s 114us/step - loss: -573.3844 - val_loss: -576.7942\n",
      "Epoch 37/50\n",
      "755/755 [==============================] - 0s 102us/step - loss: -574.9462 - val_loss: -577.4320\n",
      "Epoch 38/50\n",
      "755/755 [==============================] - 0s 127us/step - loss: -577.2712 - val_loss: -578.4129\n",
      "Epoch 39/50\n",
      "755/755 [==============================] - 0s 119us/step - loss: -576.5641 - val_loss: -577.7697\n",
      "Epoch 40/50\n",
      "755/755 [==============================] - 0s 102us/step - loss: -578.4752 - val_loss: -579.4999\n",
      "Epoch 41/50\n",
      "755/755 [==============================] - 0s 90us/step - loss: -578.5860 - val_loss: -580.2057\n",
      "Epoch 42/50\n",
      "755/755 [==============================] - 0s 118us/step - loss: -579.7848 - val_loss: -580.6769\n",
      "Epoch 43/50\n",
      "755/755 [==============================] - 0s 100us/step - loss: -579.4829 - val_loss: -580.9791\n",
      "Epoch 44/50\n",
      "755/755 [==============================] - 0s 129us/step - loss: -580.7557 - val_loss: -581.6114\n",
      "Epoch 45/50\n",
      "755/755 [==============================] - 0s 86us/step - loss: -581.2396 - val_loss: -583.5083\n",
      "Epoch 46/50\n",
      "755/755 [==============================] - 0s 102us/step - loss: -582.9267 - val_loss: -581.1373\n",
      "Epoch 47/50\n",
      "755/755 [==============================] - 0s 85us/step - loss: -583.4823 - val_loss: -584.0910\n",
      "Epoch 48/50\n",
      "755/755 [==============================] - 0s 99us/step - loss: -585.0805 - val_loss: -580.5283\n",
      "Epoch 49/50\n",
      "755/755 [==============================] - 0s 91us/step - loss: -584.3812 - val_loss: -586.6581\n",
      "Epoch 50/50\n",
      "755/755 [==============================] - 0s 92us/step - loss: -585.0969 - val_loss: -585.2816\n"
     ]
    }
   ],
   "source": [
    "hist = vae.fit(x_train,\n",
    "        x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_train,x_train))\n",
    "\n",
    "encoder = Model(x, z_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = encoder.predict(x_train, batch_size=batch_size)\n",
    "z_test = encoder.predict(x_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 10), (333, 10))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train.shape, z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83958435, -0.3021657 , -0.96403253, ..., -1.0492758 ,\n",
       "        -0.983578  , -2.1865983 ],\n",
       "       [-0.6436971 , -0.23082763, -0.5861949 , ..., -0.18810788,\n",
       "        -1.4622672 , -1.6269703 ],\n",
       "       [-1.0581148 ,  1.6171075 ,  0.2241547 , ...,  0.697038  ,\n",
       "        -0.4279828 ,  0.4540967 ],\n",
       "       ...,\n",
       "       [-0.07294971, -0.71697307, -2.2183113 , ..., -0.32586256,\n",
       "        -0.89865613, -1.7639611 ],\n",
       "       [ 0.15232477,  1.02123   , -1.992648  , ..., -3.0430787 ,\n",
       "         0.9377557 , -0.5586691 ],\n",
       "       [ 0.50714535,  1.053878  , -1.9514117 , ..., -2.5293362 ,\n",
       "         1.3194729 ,  0.4116425 ]], dtype=float32)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.4878479898113108, -0.23557822307347814, ...,\n",
       "        0.2047541382419316, 0.0, 1.0],\n",
       "       [0.0, 1.8098741311576565, 0.7469760522524025, ...,\n",
       "        0.27794649101708274, 0.0, 0.0],\n",
       "       [0.0, 1.8098741311576565, 0.3159554267026738, ...,\n",
       "        0.5434321963520068, 0.0, 0.0],\n",
       "       ...,\n",
       "       [0.0, 1.8098741311576565, -0.9248494901570484, ...,\n",
       "        0.5434321963520068, 0.0, 1.0],\n",
       "       [3.0, 1.8098741311576565, -0.923382115585833, ...,\n",
       "        0.5434321963520068, 0.0, 1.0],\n",
       "       [3.0, 1.8098741311576565, -0.9827779300879173, ...,\n",
       "        0.5434321963520068, 0.0, 1.0]], dtype=object)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수저장\n",
    "import pickle # 파이썬 객체저장을 위한 모듈\n",
    "\n",
    "if df == 'all':\n",
    "    file_nm = './pickles/vae_all.p'\n",
    "elif df == 'main':\n",
    "    file_nm = './pickles/vae_main.p'\n",
    "elif df == 'core':\n",
    "    file_nm = './pickles/vae_core.p'\n",
    "   \n",
    "    \n",
    "    \n",
    "# 파이썬 객체 상태로 저장하기\n",
    "with open(file_nm, 'wb') as file:  # hello.txt 파일을 바이너리 쓰기 모드(wb)\n",
    "    pickle.dump(z_train, file)\n",
    "    pickle.dump(z_test, file)\n",
    "    pickle.dump(y_train, file)\n",
    "    pickle.dump(y_test, file)\n",
    "    pickle.dump(train_set, file)\n",
    "    pickle.dump(test_set, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
