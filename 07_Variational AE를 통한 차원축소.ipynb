{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원의 저주\n",
    "\n",
    "차원이 증가하면 그것을 표현하기 위한 데이터의 수가 기하급수적으로 증가한다.\n",
    "\n",
    "(일정 차원이 넘으면 분류기의 성능은 점점 떨어져 0으로 수렴함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AE는 입력값보다 작은 차원을 갖는 hidden layer를 이용해 데이터 속에 숨어있는 변수를 발굴할 수 있게 해준다.\n",
    "\n",
    "흔히 사용되는 PCA는 선형적인 한계가 있다. 하지만 AE는 뉴런이 갖고 있는 non-linear 및 constraints로 인해 훨씬 뛰어난 차원 축소 능력을 가지고 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<VAE와 AE의 차이>\n",
    "\n",
    "VAE는 AE와 비슷하지만 약간 다른점이 존재한다. z가 training data와 특별이 관련이 없이 단순히 계산 중간에 나오는 한 값일 뿐이라면 VAE에서의 latent variable인 z는 continouous한 분포를 갖는 random variable이라는 점이 중요한 차이다. 이 latent variable z의 분포는 training 과정에서의 data로부터 학습된다.\n",
    "(즉, VAE는 z를 좀 더 다루기 쉬운 우리가 잘 아는 분포(가우시안)의 형태를 띄게 만들어 지는 것\n",
    "\n",
    "결론적으로, AE와 다른 점은 z 하나하나를 \"모으고\", \"흔들어서\", z 공간을 더 촘촘히 채워줘서 더 유용한 z 공간을 만든다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://blog.naver.com/PostView.nhn?blogId=laonple&logNo=220880813236&parentCategoryNo=&categoryNo=18&viewDate=&isShowPopularPosts=true&from=search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA vs VAE vs GAN\n",
    "https://spark-in.me/post/playing-with-vae-umap-pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IN 파일\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Add, Multiply\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import mnist\n",
    "from random import *\n",
    "from vae_concrete import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 변경값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구분 최초 설정 필요\n",
    "\n",
    "df = 'core'\n",
    "target_temp_df = 'Y'  # 정상:부실의 데이터 비율을 맞추기 위한 데이터셋을 사용할 건지 여부 (데이터스케일링 쥬피터 결과 기준)\n",
    "\n",
    "# main/all/core 3가지로 설정 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# core설정시 확인해야 함\n",
    "# R을 통해 확인한 stepwise 유의 변수 리스트\n",
    "core_factors = ['DR00000136','6000201001O0','6000903016D1','FNMKFN02','6000901002D1','S41000210FD1',\n",
    "'6000207003O0','DR00000052','6000906001D6','DR00000156','6000901001D3','DR00000082',\n",
    "'S41000210FD2','6000902001D2','6000908001D3','6000904001D3','6000908001D2','S41B0D1009O0',\n",
    "'6000901002D3','6000903001D2','6000403001O0','CO10100170O0','DR00000113','6000908001D7']\n",
    "\n",
    "#  키별로 비율 배분이 잘 됐는지 확인\n",
    "if df == 'all':\n",
    "    max_idx = 707\n",
    "else:\n",
    "    max_idx = 124\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # 파이썬 객체저장을 위한 모듈\n",
    "\n",
    "# 파이썬 객체 읽어오기\n",
    "\n",
    "if target_temp_df != 'Y':\n",
    "    if df == 'all':\n",
    "        with open('./pickles/dataset_all.p', 'rb') as file:    # hello.txt 파일을 바이너리 읽기 모드(rb)로 열기\n",
    "            train_set = pickle.load(file)\n",
    "            test_set = pickle.load(file)\n",
    "    else:\n",
    "        with open('./pickles/dataset_main.p', 'rb') as file:    # hello.txt 파일을 바이너리 읽기 모드(rb)로 열기\n",
    "            train_set = pickle.load(file)\n",
    "            test_set = pickle.load(file)\n",
    "else:\n",
    "# 정상:부실의 데이터 비율 조정 기준\n",
    "    if df == 'all':\n",
    "        with open('./pickles/data6vs4_all.p', 'rb') as file:    # hello.txt 파일을 바이너리 읽기 모드(rb)로 열기\n",
    "            temp_train_set = pickle.load(file)\n",
    "            temp_test_set = pickle.load(file)\n",
    "            af_cols = pickle.load(file)\n",
    "    else:\n",
    "        with open('./pickles/data6vs4_main.p', 'rb') as file:    # hello.txt 파일을 바이너리 읽기 모드(rb)로 열기\n",
    "            temp_train_set = pickle.load(file)\n",
    "            temp_test_set = pickle.load(file)\n",
    "            af_cols = pickle.load(file)\n",
    "            \n",
    "# 필요없는 열 삭제\n",
    "train_set = temp_train_set.drop(['index', 0, max_idx-1,max_idx],axis=1)  # 열삭제\n",
    "test_set = temp_test_set.drop(['index', 0, max_idx-1,max_idx],axis=1)  # 열삭제\n",
    "\n",
    "\n",
    "# 항목명 (열명) 셋팅\n",
    "factor_cols = list(af_cols[1:-2])\n",
    "train_set.columns = factor_cols\n",
    "test_set.columns = factor_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core인 경우 main에서 핵심 변수만 추림\n",
    "\n",
    "if df == 'core':\n",
    "    final_factors = ['key', 'industry', 'label']\n",
    "    final_factors = final_factors + core_factors\n",
    "    train_set = train_set[final_factors]\n",
    "    test_set = test_set[final_factors]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('core', (755, 27), (333, 27))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분리 및 타입변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "cols = train_set.columns.values\n",
    "train_info = train_set[cols[0:3]]\n",
    "x_train = train_set[cols[3:]]\n",
    "y_train = train_set['label']\n",
    "train_len = x_train.shape[0]\n",
    "\n",
    "cols = test_set.columns.values\n",
    "test_info = test_set[cols[0:3]]\n",
    "x_test = test_set[cols[3:]]\n",
    "y_test = test_set['label']\n",
    "test_len = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 24), (755,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE 모델링 ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = x_train.shape[1] # 가로 열, 주의! 설명항목 제외\n",
    "n = x_train.shape[0] # 세로 행 \n",
    "original_dim = m \n",
    "intermediate_dim = 256\n",
    "\n",
    "# latent vector  z 의 차원   32\n",
    "if m >= 100:\n",
    "    latent_dim = 32\n",
    "elif m >= 50:\n",
    "    latent_dim = 16\n",
    "else:\n",
    "    latent_dim = 10   # 최소 10개 이상은 지정되어야 함. CNN 필터 사이즈 스캔 오류 가능\n",
    "    \n",
    "batch_size = 100 # 100\n",
    "epochs = 50   # 50\n",
    "epsilon_std = 1 # 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE loss 함수 참고\n",
    "https://www.facebook.com/groups/TensorFlowKR/permalink/524873987853664/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nll(y_true, y_pred):\n",
    "    \"\"\" Negative log likelihood (Bernoulli). \"\"\"\n",
    "\n",
    "    # keras.losses.binary_crossentropy gives the mean\n",
    "    # over the last axis. we require the sum\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "\n",
    "class KLDivergenceLayer(Layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    KL을 사용하는 의미는 q0(z|x) ( x 를 받고 z 를 뱉어내는 인코더 ) 와 \n",
    "    p(z) = Normal distribution (mean= 0 stddv = 1) 의 정보량의 차이가 얼마나 나는가를 보기 위해 사용\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" \n",
    "    VAE loss = reconstruction_loss + regularizaion_loss\n",
    "    \n",
    "    1) reconstruction : AE의 입력 X와 출력 X'의 차이에 대한 loss\n",
    "    2) reqularization : -0.5 * (1 + log_z_var - z_mean^2 - z_var)\n",
    "       z_mean과 z_var는 z들의 (다시 말해 z 전체의) mean과 var가 아니다. \n",
    "       z 각각, 하나하나의 mean과 var이다. 하나하나의 mean과 var 용어 때문에 헷갈린다면 \n",
    "       (AE에서의 z와 같은) z와 z_흔들기정도 정도로 이해하면 더 쉽다.\n",
    "       x 하나하나에 대한 z 하나하나를 확률적으로 보고 학습 하겠다는 것이다.\n",
    "       \n",
    "    * z_var - log_z_var는 z_var가 1일때 최소화 된다. 즉, z_var를 1에 가깝게, 1보다 너무 크지도 작지도 않게 하라는 뜻이다\n",
    "      \"랜덤하게 흔드는\" 것을 어느 정도는 적당히 흔들어 주라는 뜻이 된다. 그래야 거기서 얘기한 \"공간 채우기\" 효과를 낼 수 있기 때문이다.\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Sequential([\n",
    "    Dense(intermediate_dim, input_dim=latent_dim, activation='relu'),\n",
    "    Dense(original_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "z_mu = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
    "z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n",
    "\n",
    "\"\"\"\n",
    "z를 학습할때마다 랜덤하게 흔들어줌\n",
    "z공간을 더 많이 학습된 공간으로 채워 준다. 결국 Decoder 입장에서 z 공간이 훨씬 더 믿을 만한 (유용한) 공간이 됨\n",
    "\"\"\"\n",
    "eps = Input(tensor=K.random_normal(stddev=epsilon_std,\n",
    "                                   shape=(K.shape(x)[0], latent_dim)))\n",
    "z_eps = Multiply()([z_sigma, eps])\n",
    "z = Add()([z_mu, z_eps])\n",
    "\n",
    "x_pred = decoder(z)\n",
    "\n",
    "vae = Model(inputs=[x, eps], outputs=x_pred)\n",
    "vae.compile(optimizer='rmsprop', loss=nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "x_train = x_train.reshape(-1, original_dim)\n",
    "x_test = x_test.reshape(-1, original_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 24), (333, 24))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 755 samples, validate on 755 samples\n",
      "Epoch 1/50\n",
      "755/755 [==============================] - 3s 4ms/step - loss: 13.9800 - val_loss: -58.5278\n",
      "Epoch 2/50\n",
      "755/755 [==============================] - 0s 82us/step - loss: -168.0007 - val_loss: -336.7396\n",
      "Epoch 3/50\n",
      "755/755 [==============================] - 0s 82us/step - loss: -376.8447 - val_loss: -415.9231\n",
      "Epoch 4/50\n",
      "755/755 [==============================] - 0s 70us/step - loss: -435.0832 - val_loss: -451.7978\n",
      "Epoch 5/50\n",
      "755/755 [==============================] - 0s 62us/step - loss: -471.8938 - val_loss: -487.2570\n",
      "Epoch 6/50\n",
      "755/755 [==============================] - 0s 77us/step - loss: -492.9308 - val_loss: -505.8073\n",
      "Epoch 7/50\n",
      "755/755 [==============================] - 0s 74us/step - loss: -507.9015 - val_loss: -516.8162\n",
      "Epoch 8/50\n",
      "755/755 [==============================] - 0s 75us/step - loss: -518.9505 - val_loss: -512.6467\n",
      "Epoch 9/50\n",
      "755/755 [==============================] - 0s 77us/step - loss: -525.5577 - val_loss: -530.3773\n",
      "Epoch 10/50\n",
      "755/755 [==============================] - 0s 67us/step - loss: -530.3597 - val_loss: -536.9615\n",
      "Epoch 11/50\n",
      "755/755 [==============================] - 0s 78us/step - loss: -535.9108 - val_loss: -542.2071\n",
      "Epoch 12/50\n",
      "755/755 [==============================] - 0s 98us/step - loss: -541.4967 - val_loss: -536.4863\n",
      "Epoch 13/50\n",
      "755/755 [==============================] - 0s 79us/step - loss: -545.0316 - val_loss: -548.5610\n",
      "Epoch 14/50\n",
      "755/755 [==============================] - 0s 125us/step - loss: -549.9211 - val_loss: -541.5611\n",
      "Epoch 15/50\n",
      "755/755 [==============================] - 0s 98us/step - loss: -552.2392 - val_loss: -551.4232\n",
      "Epoch 16/50\n",
      "755/755 [==============================] - 0s 91us/step - loss: -556.1521 - val_loss: -559.1982\n",
      "Epoch 17/50\n",
      "755/755 [==============================] - 0s 74us/step - loss: -558.1425 - val_loss: -558.5323\n",
      "Epoch 18/50\n",
      "755/755 [==============================] - 0s 65us/step - loss: -559.9462 - val_loss: -561.5717\n",
      "Epoch 19/50\n",
      "755/755 [==============================] - 0s 63us/step - loss: -562.4532 - val_loss: -563.2538\n",
      "Epoch 20/50\n",
      "755/755 [==============================] - 0s 73us/step - loss: -564.6611 - val_loss: -566.2753\n",
      "Epoch 21/50\n",
      "755/755 [==============================] - 0s 58us/step - loss: -564.1067 - val_loss: -566.9313\n",
      "Epoch 22/50\n",
      "755/755 [==============================] - 0s 73us/step - loss: -565.9760 - val_loss: -568.1902\n",
      "Epoch 23/50\n",
      "755/755 [==============================] - 0s 71us/step - loss: -566.2251 - val_loss: -569.4625\n",
      "Epoch 24/50\n",
      "755/755 [==============================] - 0s 63us/step - loss: -568.5019 - val_loss: -567.6867\n",
      "Epoch 25/50\n",
      "755/755 [==============================] - 0s 69us/step - loss: -567.8314 - val_loss: -570.1462\n",
      "Epoch 26/50\n",
      "755/755 [==============================] - 0s 71us/step - loss: -570.6652 - val_loss: -570.7205\n",
      "Epoch 27/50\n",
      "755/755 [==============================] - 0s 62us/step - loss: -570.0576 - val_loss: -572.4356\n",
      "Epoch 28/50\n",
      "755/755 [==============================] - 0s 78us/step - loss: -572.6932 - val_loss: -572.0627\n",
      "Epoch 29/50\n",
      "755/755 [==============================] - 0s 71us/step - loss: -571.1487 - val_loss: -571.6845\n",
      "Epoch 30/50\n",
      "755/755 [==============================] - 0s 58us/step - loss: -573.0090 - val_loss: -573.4503\n",
      "Epoch 31/50\n",
      "755/755 [==============================] - 0s 77us/step - loss: -573.1080 - val_loss: -572.9108\n",
      "Epoch 32/50\n",
      "755/755 [==============================] - 0s 89us/step - loss: -574.4210 - val_loss: -565.0526\n",
      "Epoch 33/50\n",
      "755/755 [==============================] - 0s 95us/step - loss: -572.8948 - val_loss: -575.9527\n",
      "Epoch 34/50\n",
      "755/755 [==============================] - 0s 110us/step - loss: -575.0602 - val_loss: -577.5154\n",
      "Epoch 35/50\n",
      "755/755 [==============================] - 0s 67us/step - loss: -575.4865 - val_loss: -577.9001\n",
      "Epoch 36/50\n",
      "755/755 [==============================] - 0s 79us/step - loss: -577.0267 - val_loss: -578.9944\n",
      "Epoch 37/50\n",
      "755/755 [==============================] - 0s 57us/step - loss: -577.3909 - val_loss: -580.3396\n",
      "Epoch 38/50\n",
      "755/755 [==============================] - 0s 83us/step - loss: -578.6331 - val_loss: -578.7780\n",
      "Epoch 39/50\n",
      "755/755 [==============================] - 0s 59us/step - loss: -579.3090 - val_loss: -580.3734\n",
      "Epoch 40/50\n",
      "755/755 [==============================] - 0s 82us/step - loss: -579.8157 - val_loss: -582.0177\n",
      "Epoch 41/50\n",
      "755/755 [==============================] - 0s 78us/step - loss: -581.9918 - val_loss: -578.5004\n",
      "Epoch 42/50\n",
      "755/755 [==============================] - 0s 73us/step - loss: -581.3413 - val_loss: -581.8781\n",
      "Epoch 43/50\n",
      "755/755 [==============================] - 0s 114us/step - loss: -583.3432 - val_loss: -580.3850\n",
      "Epoch 44/50\n",
      "755/755 [==============================] - 0s 63us/step - loss: -582.7605 - val_loss: -583.1312\n",
      "Epoch 45/50\n",
      "755/755 [==============================] - 0s 91us/step - loss: -584.4914 - val_loss: -585.8884\n",
      "Epoch 46/50\n",
      "755/755 [==============================] - 0s 77us/step - loss: -585.4652 - val_loss: -585.0206\n",
      "Epoch 47/50\n",
      "755/755 [==============================] - 0s 87us/step - loss: -585.5968 - val_loss: -582.3336\n",
      "Epoch 48/50\n",
      "755/755 [==============================] - 0s 91us/step - loss: -586.1392 - val_loss: -586.6343\n",
      "Epoch 49/50\n",
      "755/755 [==============================] - 0s 100us/step - loss: -586.7435 - val_loss: -588.0120\n",
      "Epoch 50/50\n",
      "755/755 [==============================] - 0s 104us/step - loss: -587.0551 - val_loss: -587.6243\n"
     ]
    }
   ],
   "source": [
    "hist = vae.fit(x_train,\n",
    "        x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_train,x_train))\n",
    "\n",
    "encoder = Model(x, z_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = encoder.predict(x_train, batch_size=batch_size)\n",
    "z_test = encoder.predict(x_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 10), (333, 10))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train.shape, z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 복원\n",
    "x_decoded = decoder.predict(z_test)\n",
    "x_decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 24)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수저장\n",
    "import pickle # 파이썬 객체저장을 위한 모듈\n",
    "\n",
    "if df == 'all':\n",
    "    file_nm = './pickles/vae_all.p'\n",
    "elif df == 'main':\n",
    "    file_nm = './pickles/vae_main.p'\n",
    "elif df == 'core':\n",
    "    file_nm = './pickles/vae_core.p'\n",
    "   \n",
    "    \n",
    "    \n",
    "# 파이썬 객체 상태로 저장하기\n",
    "with open(file_nm, 'wb') as file:  # hello.txt 파일을 바이너리 쓰기 모드(wb)\n",
    "    pickle.dump(z_train, file)\n",
    "    pickle.dump(z_test, file)\n",
    "    pickle.dump(y_train, file)\n",
    "    pickle.dump(y_test, file)\n",
    "    pickle.dump(train_set, file)\n",
    "    pickle.dump(test_set, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755, 24)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755, 1, 24, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape_temp = x_train.reshape(-1,1,x_train.shape[1],1)\n",
    "input_shape = input_shape_temp.shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0] % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755, 1, 24, 1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-299f6f352ca9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "a = (batch_size,) + input_shape\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up model...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-ebfaba07317b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_disc_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# input_shape 적용시 3차원 이하(초과시 수정필요)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# model.plot(std_dev=1.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\DataSientist\\S_Project\\vae_concrete.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x_train, num_epochs, batch_size, val_split, learning_rate, reset_model)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m#         self.num_epochs = num_epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[1;31m#         if reset_model:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;31m#             self._set_model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\DataSientist\\S_Project\\vae_concrete.py\u001b[0m in \u001b[0;36m_set_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mQ_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Setting up model...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mQ_4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mQ_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mQ_z_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_cont_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "model = VAE(latent_disc_dim=10, input_shape=input_shape[1:], filters = (4,4))  # input_shape 적용시 3차원 이하(초과시 수정필요)\n",
    "model.fit(x_train, num_epochs=1)\n",
    "# model.plot(std_dev=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
